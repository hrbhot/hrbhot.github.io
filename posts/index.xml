<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Mémo de Yin </title>
		<link>https://hrbhot.github.io/posts/</link>
		<description>Recent content in Posts on Mémo de Yin </description>
		<generator>Hugo -- gohugo.io</generator>
		<language>zh-hans</language>
		<lastBuildDate>Wed, 10 Jun 2020 00:16:55 +0200</lastBuildDate>
		<atom:link href="https://hrbhot.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Docker安装RabbitMQ</title>
			<link>https://hrbhot.github.io/posts/docker%E5%AE%89%E8%A3%85rabbitmq/</link>
			<pubDate>Wed, 10 Jun 2020 00:16:55 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/docker%E5%AE%89%E8%A3%85rabbitmq/</guid>
			<description>docker 一键启动
docker run -d &amp;ndash;restart always &amp;ndash;name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management
端口 5672 为RabbitMQ服务器监听的 TCP 端口
127.0.0.1:15672 为RabbitMQ管理工具监听的http端口 ，通过这个地址访问管理rabbitMQ 默认用户名 guest 密码 guest</description>
			<content type="html"><![CDATA[<p>docker 一键启动</p>

<p>docker run -d &ndash;restart always &ndash;name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management</p>

<p>端口 5672 为RabbitMQ服务器监听的 TCP 端口</p>

<p>127.0.0.1:15672 为RabbitMQ管理工具监听的http端口  ，通过这个地址访问管理rabbitMQ 默认用户名 guest 密码 guest</p>
]]></content>
		</item>
		
		<item>
			<title>命令行下载b站视频</title>
			<link>https://hrbhot.github.io/posts/%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BDb%E7%AB%99%E8%A7%86%E9%A2%91/</link>
			<pubDate>Sun, 07 Jun 2020 12:28:23 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BDb%E7%AB%99%E8%A7%86%E9%A2%91/</guid>
			<description>看b站有时候很卡，使用annie这个工具把视频下载到本地观看，和youtuble-dl差不多。
 下载安装包
wget https://github.com/iawia002/annie/releases/download/0.10.1/annie_0.10.1_Linux_64-bit.tar.gz  或者curl命令 下载
curl -LO https://github.com/iawia002/annie/releases/download/0.10.1/annie_0.10.1_Linux_64-bit.tar.gz  解压缩,并删除安装文件
tar zxvf *.gz rm *.gz  运行 下载高清的视频 可以先用 annie -i b站链接地址 ，查看支撑的清晰度，80 是1080P
  ./annie -f 80 b站链接地址
如果下载很多视频 可以把视频放在一个link.txt文件中。使用下面命令下载
./annie -f 80 -F link.txt
 如果多视频下载做个简单的后台运行脚本 down_b_video.sh
nohup ./annie -f 80 -F link.txt &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;   </description>
			<content type="html"><![CDATA[<p>看b站有时候很卡，使用annie这个工具把视频下载到本地观看，和youtuble-dl差不多。</p>

<ol>
<li><p>下载安装包</p>

<pre><code>wget https://github.com/iawia002/annie/releases/download/0.10.1/annie_0.10.1_Linux_64-bit.tar.gz
</code></pre>

<p>或者curl命令 下载</p>

<pre><code>curl -LO https://github.com/iawia002/annie/releases/download/0.10.1/annie_0.10.1_Linux_64-bit.tar.gz
</code></pre></li>

<li><p>解压缩,并删除安装文件</p>

<pre><code>tar zxvf *.gz
rm *.gz 
</code></pre></li>

<li><p>运行 下载高清的视频
可以先用 annie -i b站链接地址 ，查看支撑的清晰度，80 是1080P</p></li>
</ol>

<p>./annie -f 80 b站链接地址</p>

<p>如果下载很多视频 可以把视频放在一个link.txt文件中。使用下面命令下载</p>

<p>./annie -f 80 -F link.txt</p>

<ol>
<li><p>如果多视频下载做个简单的后台运行脚本 down_b_video.sh</p>

<pre><code>nohup ./annie -f 80 -F link.txt &gt;/dev/null 2&gt;&amp;1 &amp;
</code></pre></li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>ITerm2脚本登陆ssh</title>
			<link>https://hrbhot.github.io/posts/iterm2%E8%84%9A%E6%9C%AC%E7%99%BB%E9%99%86ssh/</link>
			<pubDate>Wed, 13 May 2020 14:52:30 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/iterm2%E8%84%9A%E6%9C%AC%E7%99%BB%E9%99%86ssh/</guid>
			<description>ITerm2 设置脚本 免输入登陆SSH
Profiles =&amp;gt; Open profiles =&amp;gt; Edit profiles =&amp;gt; Tags + =&amp;gt; Command位置 =&amp;gt; expect Path/脚本文件名
带证书 SSH脚本 #!/usr/bin/expect -f set user root #用户名 set host YouHostIP #主机IP set empath YouPATH/host.pem #证书存放位置 set timeout -1 spawn ssh -i $empath $user@$host interact expect eof  免密码 SSH脚本 #!/usr/bin/expect -f set user root #用户名 set host YouHostIP #主机IP set password YouPassword #密码 set timeout -1 spawn ssh $user@$host expect { &amp;quot;(yes/no)?</description>
			<content type="html"><![CDATA[

<p>ITerm2 设置脚本 免输入登陆SSH</p>

<p>Profiles =&gt; Open profiles =&gt; Edit profiles =&gt; Tags + =&gt; Command位置 =&gt; expect Path/脚本文件名</p>

<h3 id="带证书-ssh脚本">带证书 SSH脚本</h3>

<pre><code>#!/usr/bin/expect -f

set user root  #用户名
set host YouHostIP  #主机IP 
set empath YouPATH/host.pem  #证书存放位置
set timeout -1

spawn ssh -i $empath $user@$host
interact
expect eof
</code></pre>

<h3 id="免密码-ssh脚本">免密码 SSH脚本</h3>

<pre><code>#!/usr/bin/expect -f

set user root #用户名
set host YouHostIP  #主机IP 
set password YouPassword #密码
set timeout -1

spawn ssh $user@$host
expect {
        &quot;(yes/no)?&quot;
        {send &quot;yes\n&quot;;exp_continue}
        &quot;password:&quot;
        {send &quot;$password\n&quot;}
}
interact
expect eof
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Tradingview_pine脚本_三条ma</title>
			<link>https://hrbhot.github.io/posts/tradingview_pine%E8%84%9A%E6%9C%AC_%E4%B8%89%E6%9D%A1ma/</link>
			<pubDate>Thu, 30 Apr 2020 11:33:25 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/tradingview_pine%E8%84%9A%E6%9C%AC_%E4%B8%89%E6%9D%A1ma/</guid>
			<description>Tradingview 未付费用户有只能用三个指标的限制，如果我想看ma 20，60，120 就把资源都占用了。 利用pine编辑器6行代码节省资源，变成只占用一个指标。
// This source code is subject to the terms of the Mozilla Public License 2.0 at https://mozilla.org/MPL/2.0/ // © hrbhot //@version=4 study(title = &amp;quot;MA 20 &amp;amp; 60 &amp;amp; 120&amp;quot;, overlay = true) short = sma (close,20) //代表MA 20 mid = sma (close,60) //代表MA 60 long = sma (close,120) //代表MA 120 plot(short, color =#FF8C00, linewidth = 3) plot(mid, color =#FF4500, linewidth =3) plot(long, color =#C0C0C0, linewidth = 3)  把代码内 short,mid,long 换成自己需要的周期即可。</description>
			<content type="html"><![CDATA[<p>Tradingview 未付费用户有只能用三个指标的限制，如果我想看ma 20，60，120 就把资源都占用了。
利用pine编辑器6行代码节省资源，变成只占用一个指标。</p>

<pre><code>// This source code is subject to the terms of the Mozilla Public License 2.0 at https://mozilla.org/MPL/2.0/
// © hrbhot
//@version=4

study(title = &quot;MA 20 &amp; 60 &amp; 120&quot;, overlay = true)
short = sma (close,20)  //代表MA 20
mid = sma (close,60)    //代表MA 60
long = sma (close,120)  //代表MA 120

plot(short, color =#FF8C00, linewidth = 3)
plot(mid, color =#FF4500, linewidth =3)
plot(long, color =#C0C0C0, linewidth = 3)

</code></pre>

<p>把代码内 short,mid,long 换成自己需要的周期即可。</p>
]]></content>
		</item>
		
		<item>
			<title>给tar压缩增加进度条</title>
			<link>https://hrbhot.github.io/posts/%E7%BB%99tar%E5%8E%8B%E7%BC%A9%E5%A2%9E%E5%8A%A0%E8%BF%9B%E5%BA%A6%E6%9D%A1/</link>
			<pubDate>Tue, 28 Apr 2020 12:59:34 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E7%BB%99tar%E5%8E%8B%E7%BC%A9%E5%A2%9E%E5%8A%A0%E8%BF%9B%E5%BA%A6%E6%9D%A1/</guid>
			<description> 有点花里胡哨，在生产环境中还是建议使用 tar zcvf 这样简单的参数少的命令减少错误产生。
用pv 和du 显示进度条 需要先安装 pv工具，如ubuntu apt install pv 利用du先获得文件或目录大小，然后输出给 pv显示。
tar -cf - “要压缩的文件或者目录路径”| pv -s $(($(du -sk “要压缩的文件或者目录路径” | awk &#39;{print $1}&#39;) * 1024)) | gzip &amp;gt; {输出的文件名}.tar.gz  </description>
			<content type="html"><![CDATA[

<p>有点花里胡哨，在生产环境中还是建议使用 tar zcvf 这样简单的参数少的命令减少错误产生。</p>

<h3 id="用pv-和du-显示进度条">用pv 和du 显示进度条</h3>

<p>需要先安装 pv工具，如ubuntu apt install pv
利用du先获得文件或目录大小，然后输出给 pv显示。</p>

<pre><code>tar -cf - “要压缩的文件或者目录路径”| pv -s $(($(du -sk “要压缩的文件或者目录路径” | awk '{print $1}') * 1024)) | gzip &gt; {输出的文件名}.tar.gz
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Ssh_sftp访问权限</title>
			<link>https://hrbhot.github.io/posts/ssh_sftp%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90/</link>
			<pubDate>Fri, 24 Apr 2020 21:45:13 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/ssh_sftp%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90/</guid>
			<description>限制用户连接sftp只能访问指定的目录
 新建用户,修改密码
useradd ftpuser passwd ftpuser  设置 ssh ，注意 /data/ftp的上级目录的权限是管理员。 如果设置 ChrootDirectory %h 则为用户主目录
cd /etc/ssh cp sshd_config{,.bak} vim sshd_config #编辑 #Subsystem sftp /usr/lib/openssh/sftp-server Subsystem sftp internal-sftp Match User ftpuser ChrootDirectory /data/ftp X11Forwarding no AllowTcpForwarding no ForceCommand internal-sftp  重启 测试
service sshd restart   补充  如果多用户 可以设置用户组 Group 如下
useradd -g sftp -d /data/ftp1 -s /sbin/nologin ftp1 #添加新用户组”sftp“和用户&amp;quot;ftp1&amp;quot; Match User user1 ChrootDirectory /data/ftp X11Forwarding no AllowTcpForwarding no ForceCommand internal-sftp Match Group sftp ChrootDirectory /data/ftp1 X11Forwarding no AllowTcpForwarding no ForceCommand internal-sftp  sftp访问的目录权限上至一直到顶级根目录 ，权限最大为755不可为777 否则出现错误 ”Connection reset by peer“</description>
			<content type="html"><![CDATA[

<p>限制用户连接sftp只能访问指定的目录</p>

<ol>
<li><p>新建用户,修改密码</p>

<pre><code>useradd ftpuser
passwd ftpuser
</code></pre></li>

<li><p>设置 ssh ，注意 /data/ftp的上级目录的权限是管理员。 如果设置 ChrootDirectory %h 则为用户主目录</p>

<pre><code>cd /etc/ssh 
cp sshd_config{,.bak}
vim sshd_config

#编辑 
#Subsystem      sftp    /usr/lib/openssh/sftp-server
Subsystem sftp internal-sftp
Match User ftpuser
ChrootDirectory /data/ftp
X11Forwarding no
AllowTcpForwarding no
ForceCommand internal-sftp

</code></pre></li>

<li><p>重启 测试</p>

<pre><code>service sshd restart
</code></pre></li>
</ol>

<h3 id="补充">补充</h3>

<ol>
<li><p>如果多用户 可以设置用户组 Group 如下</p>

<pre><code>useradd -g sftp -d /data/ftp1 -s /sbin/nologin ftp1  #添加新用户组”sftp“和用户&quot;ftp1&quot; 

Match User user1
ChrootDirectory /data/ftp
X11Forwarding no
AllowTcpForwarding no
ForceCommand internal-sftp
Match Group sftp
ChrootDirectory /data/ftp1
X11Forwarding no
AllowTcpForwarding no
ForceCommand internal-sftp

</code></pre></li>

<li><p>sftp访问的目录权限上至一直到顶级根目录 ，权限最大为755不可为777 否则出现错误 ”Connection reset by peer“</p></li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>Synology安装aria2</title>
			<link>https://hrbhot.github.io/posts/synology%E5%AE%89%E8%A3%85aria2/</link>
			<pubDate>Wed, 22 Apr 2020 20:56:49 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/synology%E5%AE%89%E8%A3%85aria2/</guid>
			<description>低端的synology没有docker功能真可惜，只能手动安装 aria2
安装 bootstrap 首先ssh 连上synology
wget http://ipkg.nslu2-linux.org/feeds/optware/cs08q1armel/cross/unstable/syno-mvkw-bootstrap_1.2-7_arm.xsh chmod +x syno-mvkw-bootstrap_1.2-7_arm.xsh sh syno-mvkw-bootstrap_1.2-7_arm.xsh 如果有报错 编辑 bootstrap.sh 找到 #if ! grep Feroceon-KW /proc/cpuinfo &amp;gt;/dev/null 2&amp;gt;&amp;amp;1; then # echo &amp;quot;Error: CPU not Marvell Kirkwood, probably wrong bootstrap.xsh&amp;quot; # exit 3 #fi 在这几行前面加上# 运行脚本 sh bootstrap.sh  安装 aria2 cd /opt/bin ./ipkg update ./ipkg install http://ipkg.nslu2-linux.org/feeds/optware/cs08q1armel/cross/unstable/aria2_1.14.2-1_arm.ipk 如果有报错，删除掉重新来 ./ipkg remove aria2  编辑 aria2.conf 配置文件 mkdir -p /opt/etc/aria2 &amp;amp;&amp;amp; cd /opt/etc/aria2  vim aria2.</description>
			<content type="html"><![CDATA[

<p>低端的synology没有docker功能真可惜，只能手动安装 aria2</p>

<h3 id="安装-bootstrap">安装 bootstrap</h3>

<p>首先ssh 连上synology</p>

<pre><code>wget http://ipkg.nslu2-linux.org/feeds/optware/cs08q1armel/cross/unstable/syno-mvkw-bootstrap_1.2-7_arm.xsh
chmod +x syno-mvkw-bootstrap_1.2-7_arm.xsh
sh syno-mvkw-bootstrap_1.2-7_arm.xsh
如果有报错 编辑 bootstrap.sh

找到
#if ! grep Feroceon-KW /proc/cpuinfo &gt;/dev/null 2&gt;&amp;1; then
# echo &quot;Error: CPU not Marvell Kirkwood, probably wrong bootstrap.xsh&quot;
# exit 3
#fi
在这几行前面加上#
运行脚本
sh bootstrap.sh
</code></pre>

<h3 id="安装-aria2">安装 aria2</h3>

<pre><code>cd /opt/bin
./ipkg update
./ipkg install http://ipkg.nslu2-linux.org/feeds/optware/cs08q1armel/cross/unstable/aria2_1.14.2-1_arm.ipk
如果有报错，删除掉重新来
./ipkg remove aria2

</code></pre>

<h3 id="编辑-aria2-conf-配置文件">编辑 aria2.conf 配置文件</h3>

<pre><code>mkdir -p /opt/etc/aria2 &amp;&amp; cd /opt/etc/aria2
</code></pre>

<p>vim aria2.conf
因为在内网 所以注释掉了rpc-secret=</p>

<pre><code>## '#'开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ##
## 被注释的选项填写的是默认值, 建议在需要修改时再取消注释  ##

## 文件保存相关 ##

# 文件的保存路径(可使用绝对路径或相对路径), 默认: 当前启动位置
dir=/usr/local/caddy/www/aria2/Download
# 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M
disk-cache=64M
# 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc
# 预分配所需时间: none &lt; falloc ? trunc &lt; prealloc
# falloc和trunc则需要文件系统和内核支持
# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项
# file-allocation=none
# 断点续传
continue=true

## 下载连接相关 ##

# 最大同时下载任务数, 运行时可修改, 默认:5
max-concurrent-downloads=10
# 同一服务器连接数, 添加时可指定, 默认:1
max-connection-per-server=5
# 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M
# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载
min-split-size=10M
# 单个任务最大线程数, 添加时可指定, 默认:5
split=20
# 整体下载速度限制, 运行时可修改, 默认:0
#max-overall-download-limit=0
# 单个任务下载速度限制, 默认:0
#max-download-limit=0
# 整体上传速度限制, 运行时可修改, 默认:0
max-overall-upload-limit=1M
# 单个任务上传速度限制, 默认:0
#max-upload-limit=1000
# 禁用IPv6, 默认:false
disable-ipv6=false

## 进度保存相关 ##

# 从会话文件中读取下载任务
input-file=/opt/etc/aria2/aria2.session
# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件
save-session=/opt/etc/aria2/aria2.session
# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0
save-session-interval=60

## RPC相关设置 ##

# 启用RPC, 默认:false
enable-rpc=true
# 允许所有来源, 默认:false
rpc-allow-origin-all=true
# 允许非外部访问, 默认:false
rpc-listen-all=true
# 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同
#event-poll=select
# RPC监听端口, 端口被占用时可以修改, 默认:6800
rpc-listen-port=6800
# 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项
# rpc-secret=DOUBIToyo
# 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项
#rpc-user=&lt;USER&gt;
# 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项
#rpc-passwd=&lt;PASSWD&gt;
# 是否启用 RPC 服务的 SSL/TLS 加密,
# 启用加密后 RPC 服务需要使用 https 或者 wss 协议连接
#rpc-secure=true
# 在 RPC 服务中启用 SSL/TLS 加密时的证书文件(.pem/.crt)
#rpc-certificate=/root/xxx.pem
# 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件(.key)
#rpc-private-key=/root/xxx.key

## BT/PT下载相关 ##

# 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true
follow-torrent=true
# BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999
listen-port=51413
# 单个种子最大连接数, 默认:55
#bt-max-peers=55
# 打开DHT功能, PT需要禁用, 默认:true
enable-dht=true
# 打开IPv6 DHT功能, PT需要禁用
#enable-dht6=false
# DHT网络监听端口, 默认:6881-6999
#dht-listen-port=6881-6999
# 本地节点查找, PT需要禁用, 默认:false
#bt-enable-lpd=true
# 种子交换, PT需要禁用, 默认:true
enable-peer-exchange=true
# 每个种子限速, 对少种的PT很有用, 默认:50K
#bt-request-peer-speed-limit=50K
# 客户端伪装, PT需要
peer-id-prefix=-TR2770-
user-agent=Transmission/2.77
# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0
seed-ratio=0.1
# 强制保存会话, 即使任务已经完成, 默认:false
# 较新的版本开启后会在任务完成后依然保留.aria2文件
force-save=true
# BT校验相关, 默认:true
#bt-hash-check-seed=true
# 继续之前的BT任务时, 无需再次校验, 默认:false
bt-seed-unverified=true
# 保存磁力链接元数据为种子文件(.torrent文件), 默认:false
#bt-save-metadata=true
</code></pre>

<h3 id="设置aria2-session-用于存放下载任务-这样重启aria2也不会丢失任务了">设置aria2.session 用于存放下载任务，这样重启Aria2也不会丢失任务了</h3>

<pre><code>touch /opt/etc/aria2.session
chmod 777 /opt/etc/aria2.session
</code></pre>

<h3 id="开机启动文件">开机启动文件</h3>

<p>vim aria2.sh</p>

<pre><code>#!/bin/sh
#
# Put this file in /usr/local/etc/rc.d/aria2.sh
 
case &quot;$1&quot; in
 
stop)
    echo &quot;Stop Aria2...&quot;
    kill &quot;`pidof aria2c`&quot;
    kill &quot;`pidof aria2c`&quot;
    ;;
start)
    /opt/bin/aria2c --conf-path=/opt/etc/aria2/aria2.conf -D
    ;;
restart)
    $0 stop
    sleep 1
    $0 start
    ;;  
status)
    ps | grep aria2c | grep -v grep
    return $?
    ;;
*)
    echo &quot;usage: $0 { start | stop | restart | status}&quot; &gt;&amp;2
        exit 1
        ;;
esac
</code></pre>

<p>mv aria2.sh /usr/local/etc/rc.d/</p>

<h3 id="客户端配置">客户端配置</h3>

<p>去 <a href="https://github.com/mayswind/AriaNg/releases">https://github.com/mayswind/AriaNg/releases</a>  下载一个AllinOne</p>

<p>打开网页 在aria2设置里面 添加synology的地址 如果 最下方 提示 aria2状态 已连接，成功安装。</p>
]]></content>
		</item>
		
		<item>
			<title>Elastic_stack_kibana_apache_nginx日志</title>
			<link>https://hrbhot.github.io/posts/elastic_stack_kibana_apache%E6%97%A5%E5%BF%97/</link>
			<pubDate>Fri, 17 Apr 2020 17:17:13 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/elastic_stack_kibana_apache%E6%97%A5%E5%BF%97/</guid>
			<description>配置 Elastic和kibana监控apache/nginx 日志
elastic 监控 apache 日志  elastic stack # 开源日志平台 由elasticsearch ,logstash，kibana，beats四个组件组成 kibana # 前端web展示日志分析和内容 kafka # 消息队列 filebeat # 将系统日志可视化，把数据发送给 logstash和elasticsearch logstash # 收集分析存储工具 elasticsearch # 搜索分析存储的数据,基于JSON分布式搜索  拉es镜像 docker pull elasticsearch:6.7.0  创建es配置文件和挂载目录 cd / mkdir -p mnt/elasticsearch cd mnt/elasticsearch mkdir config mkdir matser mkdir slave chmod 777 master chmod 777 slave  调高jvm线程 vim /etc/sysctl.conf # 添加这个 vm.max_map_count=262144 # 保存后执行这个命令 sysctl -p  matser.yml cluster.</description>
			<content type="html"><![CDATA[

<p>配置 Elastic和kibana监控apache/nginx 日志</p>

<h3 id="elastic-监控-apache-日志">elastic 监控 apache 日志</h3>

<ul>
<li>elastic stack # 开源日志平台 由elasticsearch ,logstash，kibana，beats四个组件组成</li>
<li>kibana        # 前端web展示日志分析和内容</li>
<li>kafka         # 消息队列</li>
<li>filebeat      # 将系统日志可视化，把数据发送给 logstash和elasticsearch</li>
<li>logstash      # 收集分析存储工具</li>
<li>elasticsearch # 搜索分析存储的数据,基于JSON分布式搜索</li>
</ul>

<h3 id="拉es镜像">拉es镜像</h3>

<pre><code>docker pull elasticsearch:6.7.0

</code></pre>

<h3 id="创建es配置文件和挂载目录">创建es配置文件和挂载目录</h3>

<pre><code>cd  /
mkdir -p mnt/elasticsearch
cd  mnt/elasticsearch
mkdir config
mkdir matser
mkdir slave
chmod 777 master
chmod 777 slave
</code></pre>

<h3 id="调高jvm线程">调高jvm线程</h3>

<pre><code>vim /etc/sysctl.conf
# 添加这个
vm.max_map_count=262144 
# 保存后执行这个命令
sysctl -p

</code></pre>

<h3 id="matser-yml">matser.yml</h3>

<pre><code>cluster.name: elasticsearch-cluster
node.name: master
network.bind_host: 0.0.0.0
network.publish_host: `you ip`
http.port: 9200
transport.tcp.port: 9300
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
node.master: true 
node.data: true  
discovery.zen.ping.unicast.hosts: [&quot;`you ip`:9300&quot;,&quot;`you ip`:9301&quot;]
</code></pre>

<h3 id="slave-yml">slave.yml</h3>

<pre><code>
cluster.name: elasticsearch-cluster
node.name: slave
network.bind_host: 0.0.0.0
network.publish_host: `you ip`
http.port: 9202
transport.tcp.port: 9302
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
node.master: false
node.data: true  
discovery.zen.ping.unicast.hosts: [&quot;`you ip`:9300&quot;,&quot;`you ip`:9301&quot;]

</code></pre>

<h3 id="启动master">启动master</h3>

<pre><code>docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; -d -p 9200:9200 -p 9300:9300 -v /data/dev/es/mnt/elasticsearch/config/master.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data/dev/es/mnt/elasticsearch/master:/usr/share/elasticsearch/data --name es-master elasticsearch:6.7.0
</code></pre>

<p>查看是否有返回数据
curl <code>you ip</code>:9200</p>

<h3 id="启动slave">启动slave</h3>

<pre><code> docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; -d -p 9201:9201 -p 9301:9301 -v /data/dev/es/mnt/elasticsearch/config/slave.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /data/dev/es/mnt/elasticsearch/slave:/usr/share/elasticsearch/data --name es-slave elasticsearch:6.7.0
</code></pre>

<h3 id="启动kibana">启动kibana</h3>

<pre><code>docker pull kibana:6.7.0

docker run --link es-master:elasticsearch -p 5601:5601 --name kibana -d kibana:6.7.0
</code></pre>

<hr />

<h3 id="docker-compose-yml-版本">docker-compose.yml 版本</h3>

<pre><code>version: '2.2'
services:
  es01:
    image: elasticsearch:7.5.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: elasticsearch:7.5.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01
      - cluster.initial_master_nodes=es01,es02
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  kibana:
    image: kibana:7.5.1
    container_name: kibana
    restart: always
    ports:
      - &quot;5601:5601&quot;
    environment:
      I18N_LOCALE: zh-CN #汉化
    networks:
      - elastic
    links:
      - es01:elasticsearch
volumes:
  data01:
    driver: local
  data02:
    driver: local
networks:
  elastic:
    driver: bridge

</code></pre>

<hr />

<h3 id="安装-filebeat-查看-apache-日志-linux">安装 Filebeat 查看 apache 日志 linux</h3>

<ol>
<li><p>下载并安装 Filebeat</p>

<pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-amd64.deb
sudo dpkg -i filebeat-7.5.1-amd64.deb
</code></pre></li>

<li><p>编辑 /etc/filebeat/filebeat.yml</p>

<pre><code>output.elasticsearch:
hosts: [&quot;&lt;es_url&gt;&quot;]
username: &quot;elastic&quot;
password: &quot;&lt;password&gt;&quot;
setup.kibana:
host: &quot;&lt;kibana_url&gt;&quot;

</code></pre></li>

<li><p>启动和配置apache模块</p>

<pre><code>sudo filebeat modules enable apache

</code></pre></li>
</ol>

<p>在 /etc/filebeat/modules.d/apache.yml 文件中修改设置。</p>

<ol>
<li><p>启动 Filebeat</p>

<pre><code>sudo service filebeat start
</code></pre></li>
</ol>

<p>确认已从 Filebeat apache 模块成功收到数据</p>

<h3 id="安装filebeat-查看-nginx-日志">安装Filebeat 查看 nginx 日志</h3>

<ol>
<li><p>下载并安装 Filebeat</p>

<pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.5.1-amd64.deb
sudo dpkg -i filebeat-7.5.1-amd64.deb

</code></pre></li>

<li><p>修改 /etc/filebeat/filebeat.yml 以设置连接信息：</p>

<pre><code>output.elasticsearch:
hosts: [&quot;&lt;es_url&gt;&quot;]
username: &quot;elastic&quot;
password: &quot;&lt;password&gt;&quot;
setup.kibana:
host: &quot;&lt;kibana_url&gt;&quot;

</code></pre></li>

<li><p>启用和配置 nginx 模块</p>

<pre><code>sudo filebeat modules enable nginx
在 /etc/filebeat/modules.d/nginx.yml 文件中修改设置。


</code></pre></li>

<li><p>启动 Filebeat</p>

<pre><code>sudo service filebeat start
</code></pre></li>
</ol>

<p>确认已从 Filebeat nginx 模块成功收到数据</p>
]]></content>
		</item>
		
		<item>
			<title>apache服务器的域名ssl配置</title>
			<link>https://hrbhot.github.io/posts/apache%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%9F%E5%90%8D%E9%85%8D%E7%BD%AE/</link>
			<pubDate>Fri, 17 Apr 2020 10:36:04 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/apache%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%9F%E5%90%8D%E9%85%8D%E7%BD%AE/</guid>
			<description>在/etc/apache2/apache2.conf 里面添加域名配置的路径方便管理，因为要配置多域名
# Vhost IncludeOptional conf.d/vhost/*.conf  在/etc/apache2/conf.d/vhost/ 目录下增加a1.conf ，a2.conf 代表a1网站和a2网站
 在/etc/apache2/ssl/a1 目录下放置 a1网站的ssl证书文件
  a1.conf的内容如下
&amp;lt;VirtualHost *:80&amp;gt; ServerName a1.com # a1的域名 ServerAlias www.a1.com ServerAdmin admin@gmail.com #管理员邮箱 DocumentRoot /data/web # 网站存放路径 &amp;lt;Directory /data/web&amp;gt; # 网站存放路径 DirectoryIndex index.php Options FollowSymLinks AllowOverride All Require all granted &amp;lt;/Directory&amp;gt; ErrorLog ${APACHE_LOG_DIR}/a1-error.log #错误日志路径 CustomLog ${APACHE_LOG_DIR}/a1-access.log combined #访问日志路径 # ssl配置部分 &amp;lt;/VirtualHost&amp;gt; &amp;lt;IfModule mod_ssl.c&amp;gt; &amp;lt;VirtualHost *:443&amp;gt; ServerAdmin admin@gmail.com ServerName a1.com ServerAlias www.a1.com DocumentRoot /data/web	#网站存放路径 &amp;lt;Directory /data/web/&amp;gt; #网站存放路径 DirectoryIndex index.</description>
			<content type="html"><![CDATA[<ol>
<li><p>在/etc/apache2/apache2.conf 里面添加域名配置的路径方便管理，因为要配置多域名</p>

<pre><code># Vhost
IncludeOptional conf.d/vhost/*.conf
</code></pre></li>

<li><p>在/etc/apache2/conf.d/vhost/ 目录下增加a1.conf ，a2.conf 代表a1网站和a2网站</p></li>

<li><p>在/etc/apache2/ssl/a1 目录下放置 a1网站的ssl证书文件</p></li>
</ol>

<hr />

<p><strong>a1.conf</strong>的内容如下</p>

<pre><code>&lt;VirtualHost *:80&gt;
ServerName a1.com   # a1的域名
ServerAlias www.a1.com

	ServerAdmin admin@gmail.com    #管理员邮箱 
	DocumentRoot /data/web         # 网站存放路径
	&lt;Directory /data/web&gt;          # 网站存放路径
        DirectoryIndex index.php
        Options FollowSymLinks
        AllowOverride All
        Require all granted
   	&lt;/Directory&gt;
	

	ErrorLog ${APACHE_LOG_DIR}/a1-error.log              #错误日志路径
	CustomLog ${APACHE_LOG_DIR}/a1-access.log combined   #访问日志路径

# ssl配置部分

&lt;/VirtualHost&gt;  
&lt;IfModule mod_ssl.c&gt;
&lt;VirtualHost *:443&gt;
ServerAdmin admin@gmail.com
ServerName a1.com
ServerAlias www.a1.com
DocumentRoot /data/web				#网站存放路径
&lt;Directory /data/web/&gt; 				#网站存放路径
DirectoryIndex index.php
Options Indexes FollowSymLinks
AllowOverride All
Require all granted
&lt;/Directory&gt;
ErrorLog ${APACHE_LOG_DIR}/a1-ssl-error.log  			#ssl错误日志路径
CustomLog ${APACHE_LOG_DIR}/a1-ssl-access.log combined  #ssl访问日志路径
SSLEngine on
SSLCertificateFile /etc/apache2/ssl/a1/cert.pem            #证书路径
SSLCertificateKeyFile /etc/apache2/ssl/a1/key.pem          #证书路径
SSLCertificateChainFile /etc/apache2/ssl/a1/fullchain.pem  #证书路径
&lt;FilesMatch &quot;\.(cgi|shtml|phtml|php)$&quot;&gt;
SSLOptions +StdEnvVars
&lt;/FilesMatch&gt;
&lt;/VirtualHost&gt;
&lt;/IfModule&gt;

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>使用tree命令排除某目录的方法 </title>
			<link>https://hrbhot.github.io/posts/tree%E6%8E%92%E9%99%A4%E6%9F%90%E7%9B%AE%E5%BD%95/</link>
			<pubDate>Sun, 12 Apr 2020 09:34:06 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/tree%E6%8E%92%E9%99%A4%E6%9F%90%E7%9B%AE%E5%BD%95/</guid>
			<description>当前路径有如下目录文件
Config Controllers Models Routes go.mod go.sum main.go pkg  排除pkg目录
tree -I &amp;quot;./pkg&amp;quot;  得到排除的tree结果
. ├── Config │ └── Database.go ├── Controllers │ └── Todo.go ├── Models │ ├── Model.go │ └── Todos.go ├── Routes │ └── Routes.go ├── go.mod ├── go.sum └── main.go  </description>
			<content type="html"><![CDATA[<p>当前路径有如下目录文件</p>

<pre><code>Config      Controllers Models      Routes      go.mod      go.sum      main.go     pkg
</code></pre>

<p>排除pkg目录</p>

<pre><code>tree -I &quot;./pkg&quot;
</code></pre>

<p>得到排除的tree结果</p>

<pre><code>.
├── Config
│   └── Database.go
├── Controllers
│   └── Todo.go
├── Models
│   ├── Model.go
│   └── Todos.go
├── Routes
│   └── Routes.go
├── go.mod
├── go.sum
└── main.go

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Ufw简单用法</title>
			<link>https://hrbhot.github.io/posts/ufw%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/</link>
			<pubDate>Sat, 11 Apr 2020 20:00:22 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/ufw%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/</guid>
			<description> ufw 简单用法 展示当前策略
ufw status  禁止9090端口
ufw deny 9090  允许9090端口
ufw allow 9090  删除某个规则 首先查看 规则序号
ufw status numbered  删除
ufw delete 序号  只允许指定IP地址访问指定端口
例如9090端口只允许10.0.2.1访问 来规避prometheus的数据被外部发现
ufw allow from 10.0.2.1 to any port 9090  </description>
			<content type="html"><![CDATA[

<h3 id="ufw-简单用法">ufw 简单用法</h3>

<p>展示当前策略</p>

<pre><code>ufw status
</code></pre>

<p>禁止9090端口</p>

<pre><code>ufw deny 9090
</code></pre>

<p>允许9090端口</p>

<pre><code>ufw allow 9090
</code></pre>

<p>删除某个规则
首先查看 规则序号</p>

<pre><code>ufw status numbered
</code></pre>

<p>删除</p>

<pre><code>ufw delete 序号
</code></pre>

<p>只允许指定IP地址访问指定端口</p>

<p>例如9090端口只允许10.0.2.1访问 来规避prometheus的数据被外部发现</p>

<pre><code>ufw allow from 10.0.2.1 to any port 9090
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Docker安装php extension imagemagick</title>
			<link>https://hrbhot.github.io/posts/docker%E5%AE%89%E8%A3%85php_extension_imagemagick/</link>
			<pubDate>Sat, 11 Apr 2020 18:37:48 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/docker%E5%AE%89%E8%A3%85php_extension_imagemagick/</guid>
			<description>进入docker内安装 apt-get update \ &amp;amp;&amp;amp; apt-get install -y libmagickwand-6.q16-dev --no-install-recommends \ &amp;amp;&amp;amp; yes&amp;quot;&amp;quot;|pecl install imagick \ &amp;amp;&amp;amp; echo &amp;quot;extension=imagick.so&amp;quot; &amp;gt; /usr/local/etc/php/conf.d/ext-imagick.ini  yes&amp;rdquo;&amp;rdquo; | 的意思是管道传递一个参数给后面的命令让pecl静默安装。
上面代码有待优化，上述安装让docker增加了差不多200M。</description>
			<content type="html"><![CDATA[

<h3 id="进入docker内安装">进入docker内安装</h3>

<pre><code>apt-get update \
&amp;&amp; apt-get install -y libmagickwand-6.q16-dev --no-install-recommends \
&amp;&amp; yes&quot;&quot;|pecl install imagick \
&amp;&amp; echo &quot;extension=imagick.so&quot; &gt; /usr/local/etc/php/conf.d/ext-imagick.ini
</code></pre>

<p>yes&rdquo;&rdquo; | 的意思是管道传递一个参数给后面的命令让pecl静默安装。</p>

<p>上面代码有待优化，上述安装让docker增加了差不多200M。</p>
]]></content>
		</item>
		
		<item>
			<title>解决docker内不能用php发邮件问题</title>
			<link>https://hrbhot.github.io/posts/%E8%A7%A3%E5%86%B3docker%E5%86%85%E4%B8%8D%E8%83%BD%E7%94%A8php%E5%8F%91%E9%82%AE%E4%BB%B6%E9%97%AE%E9%A2%98/</link>
			<pubDate>Sat, 11 Apr 2020 18:22:25 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E8%A7%A3%E5%86%B3docker%E5%86%85%E4%B8%8D%E8%83%BD%E7%94%A8php%E5%8F%91%E9%82%AE%E4%BB%B6%E9%97%AE%E9%A2%98/</guid>
			<description>用php mail发送邮件 ，docker 提示 cant connect to remote host (127.0.0.1): Connection refused。
问题来源于sendmail
解决办法 安装ssmtp 进入docker
apt-get install -q -y ssmtp mailutils / echo &amp;quot;mailhub=smtp.gmail.com:587&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf / echo &amp;quot;AuthUser=youMail@gmail.com&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf / echo &amp;quot;AuthPass=youPassword&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf / echo &amp;quot;UseTLS=YES&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf / echo &amp;quot;UseSTARTTLS=YES&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf / # 显示 发件人 echo &amp;quot;FromLineOverride=YES&amp;quot; &amp;gt;&amp;gt; /etc/ssmtp/ssmtp.conf #如果已经在php.ini里面设置了这步可以省却 echo &amp;quot;sendmail_path=sendmail -i -t&amp;quot; &amp;gt;&amp;gt; /usr/local/etc/php/conf.d/php-sendmail.ini  测试发送 下面2个方法都可以
 echo &amp;quot;Subject: Testing Email&amp;quot; | /usr/lib/sendmail -s youMail@gmail.</description>
			<content type="html"><![CDATA[

<p>用php mail发送邮件 ，docker 提示 cant connect to remote host (127.0.0.1): Connection refused。</p>

<p>问题来源于sendmail</p>

<h3 id="解决办法-安装ssmtp">解决办法 安装ssmtp</h3>

<p>进入docker</p>

<pre><code>apt-get install -q -y ssmtp mailutils /
echo &quot;mailhub=smtp.gmail.com:587&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf /
echo &quot;AuthUser=youMail@gmail.com&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf /
echo &quot;AuthPass=youPassword&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf /
echo &quot;UseTLS=YES&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf /
echo &quot;UseSTARTTLS=YES&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf /
# 显示 发件人
echo &quot;FromLineOverride=YES&quot; &gt;&gt; /etc/ssmtp/ssmtp.conf 
#如果已经在php.ini里面设置了这步可以省却 
echo &quot;sendmail_path=sendmail -i -t&quot; &gt;&gt; /usr/local/etc/php/conf.d/php-sendmail.ini 

</code></pre>

<h3 id="测试发送">测试发送</h3>

<p>下面2个方法都可以</p>

<pre><code>
echo &quot;Subject: Testing Email&quot; | /usr/lib/sendmail -s youMail@gmail.com

echo &quot;Subject: Testing Email&quot; | /usr/sbin/sendmail -s youMail@gmail.com
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Tar命令打包排除某个目录或者文件</title>
			<link>https://hrbhot.github.io/posts/tar%E5%91%BD%E4%BB%A4%E6%89%93%E5%8C%85%E6%8E%92%E9%99%A4%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E6%88%96%E8%80%85%E6%96%87%E4%BB%B6/</link>
			<pubDate>Thu, 09 Apr 2020 17:25:29 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/tar%E5%91%BD%E4%BB%A4%E6%89%93%E5%8C%85%E6%8E%92%E9%99%A4%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E6%88%96%E8%80%85%E6%96%87%E4%BB%B6/</guid>
			<description> 用tar 打包，并排除其中某个目录或者文件。
要打包test目录的结构 . ├── 1 │ ├── 1.txt │ └── 2.md ├── 2 │ └── 2.txt └── 3  打包排除目录1 tar zcvf test.tar.gz --eclude=test/1 test  打包排除目录1 和目录2 tar zcvf test.tar.gz --exclude=test/1 --exclude=test/2 test  打包排除目录1下面所有txt文件 tar zcvf test.tar.gz --exclude=test/1/*.txt test  </description>
			<content type="html"><![CDATA[

<p>用tar 打包，并排除其中某个目录或者文件。</p>

<h3 id="要打包test目录的结构">要打包test目录的结构</h3>

<pre><code>.
├── 1
│   ├── 1.txt
│   └── 2.md
├── 2
│   └── 2.txt
└── 3
</code></pre>

<h3 id="打包排除目录1">打包排除目录1</h3>

<pre><code>tar zcvf test.tar.gz --eclude=test/1 test

</code></pre>

<h3 id="打包排除目录1-和目录2">打包排除目录1 和目录2</h3>

<pre><code>tar zcvf test.tar.gz --exclude=test/1 --exclude=test/2 test
</code></pre>

<h3 id="打包排除目录1下面所有txt文件">打包排除目录1下面所有txt文件</h3>

<pre><code>tar zcvf test.tar.gz --exclude=test/1/*.txt test

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Docker搭建Prometheus监控系统</title>
			<link>https://hrbhot.github.io/posts/docker%E6%90%AD%E5%BB%BAprometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</link>
			<pubDate>Tue, 07 Apr 2020 22:51:38 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/docker%E6%90%AD%E5%BB%BAprometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/</guid>
			<description>简述 对比zabbix，个人更喜欢prometheus。简单快捷，zabbix过重。 1. 安装prometheus收集数据和存储时间序列（TSDB） 2. 在目标机器上安装node-exporter提供metrics 数据给prometheus 3. 安装grafana 展示数据
目录结构 . ├── docker-compose.yml ├── exporter │ ├── node_exporter │ └── up.sh └── prometheus └── prometheus.yml  目标机器安装 Node Exporter 下载
wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz tar zxvf *.gz  进入node exporter目录，创建一个启动脚本 &amp;ldquo;up.sh&amp;rdquo; ,开放端口 9101 。
脚本内容如下
nohup ./node_exporter --web.listen-address=&amp;quot;:9101&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;  启动 Node exporter
./up.sh  Prometheus 监控配置 编辑 prometheus.yml 文件 放在 prometheus目录下
global: scrape_interval: 5s scrape_configs: - job_name: &#39;prometheus&#39; static_configs: - targets: [&#39;prometheus:9090&#39;] #同时监控服务本身 - job_name: &#39;linux-exporter&#39; metrics_path: /metrics static_configs: - targets: [&#39;localhost:9101&#39;] #node ip以及端口  Docker安装 Prometheus 和 Grafana docker-compose.</description>
			<content type="html"><![CDATA[

<h2 id="简述">简述</h2>

<p>对比zabbix，个人更喜欢prometheus。简单快捷，zabbix过重。
1. 安装prometheus收集数据和存储时间序列（TSDB）
2. 在目标机器上安装node-exporter提供metrics 数据给prometheus
3. 安装grafana 展示数据</p>

<h3 id="目录结构">目录结构</h3>

<pre><code>.
├── docker-compose.yml
├── exporter
│   ├── node_exporter
│   └── up.sh
└── prometheus
    └── prometheus.yml
</code></pre>

<h3 id="目标机器安装-node-exporter">目标机器安装 Node Exporter</h3>

<p>下载</p>

<pre><code>wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz

tar zxvf *.gz

</code></pre>

<p>进入node exporter目录，创建一个启动脚本 &ldquo;up.sh&rdquo; ,开放端口 9101 。</p>

<p>脚本内容如下</p>

<pre><code>nohup ./node_exporter --web.listen-address=&quot;:9101&quot; &gt;/dev/null 2&gt;&amp;1 &amp;
</code></pre>

<p>启动 Node exporter</p>

<pre><code>./up.sh
</code></pre>

<h3 id="prometheus-监控配置">Prometheus 监控配置</h3>

<p>编辑 prometheus.yml 文件 放在 prometheus目录下</p>

<pre><code>global:
  scrape_interval: 5s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090'] #同时监控服务本身
  - job_name: 'linux-exporter'
    metrics_path: /metrics
    static_configs:
      - targets: ['localhost:9101'] #node ip以及端口
</code></pre>

<h3 id="docker安装-prometheus-和-grafana">Docker安装 Prometheus 和 Grafana</h3>

<p>docker-compose.yml 文件</p>

<pre><code>version: '3'
services:
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    environment:
     TZ: Europe/Paris
    restart: always
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
            TZ: Europe/Paris
    restart: always
    ports:
      - &quot;3000:3000&quot;
    volumes:
      - grafana-storage:/var/lib/grafana
volumes:
   grafana-storage: {}
   prometheus-data: {}
</code></pre>

<p>启动 docker-compose</p>

<pre><code>docker-compose up -d
</code></pre>

<p>查看端口是否开放</p>

<p>nc -v ip地址 9090</p>

<h3 id="配置grafana">配置Grafana</h3>

<p><a href="http://ip地址:3000">http://ip地址:3000</a>
用户名密码 admin</p>

<p>添加数据源</p>

<pre><code>http://ip地址:9090
</code></pre>

<p>导入一个好看的 dashborad ,可以去官网看 <a href="https://grafana.com/grafana/dashboards">https://grafana.com/grafana/dashboards</a></p>

<pre><code>http://ip地址:3000/dashboard/import
</code></pre>

<p>输入8919 点Load导入</p>
]]></content>
		</item>
		
		<item>
			<title>Portainer 的安装</title>
			<link>https://hrbhot.github.io/posts/portainer/</link>
			<pubDate>Sun, 29 Mar 2020 13:46:55 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/portainer/</guid>
			<description> linux 安装 Portainer 是一个docker web端的控制面板,目测非常简单方便。
创建 volume docker volume create portainer_data  启动运行 portainer 通过 9000端口访问 ，初始需要设置用户名密码。
docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer  </description>
			<content type="html"><![CDATA[

<h1 id="linux-安装">linux 安装</h1>

<p>Portainer 是一个docker web端的控制面板,目测非常简单方便。</p>

<h2 id="创建-volume">创建 volume</h2>

<pre><code>docker volume create portainer_data
</code></pre>

<h2 id="启动运行-portainer">启动运行 portainer</h2>

<p>通过 9000端口访问 ，初始需要设置用户名密码。</p>

<pre><code>docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Mac命令行中用sublime打开文件</title>
			<link>https://hrbhot.github.io/posts/mac%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E7%94%A8sublime%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6/</link>
			<pubDate>Sun, 29 Mar 2020 10:27:04 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/mac%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E7%94%A8sublime%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6/</guid>
			<description> mac命令行中用sublime打开文件 使用zsh环境 编辑 bash_profile文件
vim ~/.bash_profile  在尾部添加内容
alias subl=&amp;quot;&#39;/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl&#39;&amp;quot; alias nano=&amp;quot;subl&amp;quot; export EDITOR=&amp;quot;subl&amp;quot;  重新加载 source
source ~/.bash_profile  运行 测试
subl  </description>
			<content type="html"><![CDATA[

<h1 id="mac命令行中用sublime打开文件">mac命令行中用sublime打开文件</h1>

<h2 id="使用-zsh-环境">使用<strong>zsh</strong>环境</h2>

<p>编辑 bash_profile文件</p>

<pre><code>vim ~/.bash_profile
</code></pre>

<p>在尾部添加内容</p>

<pre><code>alias subl=&quot;'/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl'&quot;
alias nano=&quot;subl&quot;
export EDITOR=&quot;subl&quot;
</code></pre>

<p>重新加载 source</p>

<pre><code>source ~/.bash_profile

</code></pre>

<p>运行 测试</p>

<pre><code>subl
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Odoo安装简述</title>
			<link>https://hrbhot.github.io/posts/odoo%E5%AE%89%E8%A3%85%E7%AE%80%E8%BF%B0/</link>
			<pubDate>Sun, 12 Jan 2020 20:22:31 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/odoo%E5%AE%89%E8%A3%85%E7%AE%80%E8%BF%B0/</guid>
			<description>odoo 安装 安装 postgresql 12 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main&amp;quot; |sudo tee /etc/apt/sources.list.d/pgdg.list sudo apt -y install postgresql-12 postgresql-client-12  创建 postgresql odoo用户和密码 sudo adduser --system --home=/opt/odoo --group odoo  测试 postgresql sudo su - postgres psql  配置 postgresql 允许外部访问 vim /etc/postgresql/12/main/postgresql.conf # Listen on all interfaces listen_addresses = &#39;*&#39; ### python3环境准备  sudo apt install python3-dev python3-pip -y sudo apt install build-essential libxslt-dev libzip-dev libldap2-dev libsasl2-dev libssl-dev -y</description>
			<content type="html"><![CDATA[

<h2 id="odoo-安装">odoo 安装</h2>

<h3 id="安装-postgresql-12">安装 postgresql 12</h3>

<pre><code>wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
echo &quot;deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main&quot; |sudo tee  /etc/apt/sources.list.d/pgdg.list
sudo apt -y install postgresql-12 postgresql-client-12

</code></pre>

<h3 id="创建-postgresql-odoo用户和密码">创建 postgresql odoo用户和密码</h3>

<pre><code>sudo adduser --system --home=/opt/odoo --group odoo

</code></pre>

<h3 id="测试-postgresql">测试 postgresql</h3>

<pre><code>sudo su - postgres
psql
</code></pre>

<h3 id="配置-postgresql-允许外部访问">配置 postgresql 允许外部访问</h3>

<pre><code>vim /etc/postgresql/12/main/postgresql.conf 

# Listen on all interfaces
listen_addresses = '*'

### python3环境准备

</code></pre>

<p>sudo apt install python3-dev python3-pip -y
sudo apt install build-essential libxslt-dev libzip-dev libldap2-dev libsasl2-dev libssl-dev -y</p>

<h3 id="下载odoo-源码">下载odoo 源码</h3>

<pre><code>创建odoo目录 并进入

git clone https://github.com/odoo/odoo.git -b 12.0 --depth=1 
pip3 install -r requirements.txt
pip3 install num2words phonenumbers psycopg2-binary watchdog xlwt
</code></pre>

<h3 id="设置odoo-数据库配置">设置odoo 数据库配置</h3>

<pre><code>cp ./debian/odoo.conf ./odoo12.conf

</code></pre>

<p>修改 odoo12.conf</p>

<pre><code>[options]
; This is the password that allows database operations:
admin_passwd = admin
db_host = 127.0.0.1 //本地服务器
db_port = False
db_user = odoo
db_password = password  //密码
;addons_path = /usr/lib/python3/dist-packages/odoo/addons

</code></pre>

<h3 id="启动-odoo">启动 odoo</h3>

<p>./odoo-bin -c odoo12.conf</p>
]]></content>
		</item>
		
		<item>
			<title>Mac Font Chrome</title>
			<link>https://hrbhot.github.io/posts/mac-font-chrome/</link>
			<pubDate>Sun, 12 Jan 2020 19:19:07 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/mac-font-chrome/</guid>
			<description> mac下chrome 字体发虚 运行
defaults write -g CGFontRenderingFontSmoothingDisabled -bool NO  </description>
			<content type="html"><![CDATA[

<h2 id="mac下chrome-字体发虚">mac下chrome 字体发虚</h2>

<p>运行</p>

<pre><code>defaults write -g CGFontRenderingFontSmoothingDisabled -bool NO

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Linux前台进程切换到后台</title>
			<link>https://hrbhot.github.io/posts/linux%E5%89%8D%E5%8F%B0%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E5%88%B0%E5%90%8E%E5%8F%B0/</link>
			<pubDate>Wed, 06 Nov 2019 23:33:55 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/linux%E5%89%8D%E5%8F%B0%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E5%88%B0%E5%90%8E%E5%8F%B0/</guid>
			<description>command &amp;amp; //将进程放在后台执行 ctrl-z //暂停当前进程 并放入后台 jobs //查看当前后台任务 bg //将任务转为后台执行 fg //将任务调回前台</description>
			<content type="html"><![CDATA[<p>command &amp;   //将进程放在后台执行
ctrl-z      //暂停当前进程 并放入后台
jobs        //查看当前后台任务
bg          //将任务转为后台执行
fg          //将任务调回前台</p>
]]></content>
		</item>
		
		<item>
			<title>Docker环境下nextcloud配置smb服务</title>
			<link>https://hrbhot.github.io/posts/docker%E7%8E%AF%E5%A2%83%E4%B8%8Bnextcloud%E9%85%8D%E7%BD%AEsmb%E6%9C%8D%E5%8A%A1/</link>
			<pubDate>Wed, 06 Nov 2019 23:30:51 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/docker%E7%8E%AF%E5%A2%83%E4%B8%8Bnextcloud%E9%85%8D%E7%BD%AEsmb%E6%9C%8D%E5%8A%A1/</guid>
			<description>在nextcloud docker环境下增加外部存储 smb的方法 外部存储-&amp;gt; 添加本地 路径 /data/smb -&amp;gt; /etc/samba/smb.conf 定位配置路径 docker持久目录下的data/smm b目录。  原理是把smb的目录位置，设置成nextcloud内部的本地路径，因为nextcloud的smb配置规则不清晰，调试麻烦 。
~</description>
			<content type="html"><![CDATA[

<h1 id="在nextcloud-docker环境下增加外部存储-smb的方法">在nextcloud docker环境下增加外部存储 smb的方法</h1>

<pre><code>外部存储-&gt; 添加本地 路径 /data/smb -&gt; /etc/samba/smb.conf 定位配置路径 docker持久目录下的data/smm
b目录。
</code></pre>

<p>原理是把smb的目录位置，设置成nextcloud内部的本地路径，因为nextcloud的smb配置规则不清晰，调试麻烦
。</p>

<p>~</p>
]]></content>
		</item>
		
		<item>
			<title>Samba服务器</title>
			<link>https://hrbhot.github.io/posts/samba%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
			<pubDate>Wed, 30 Oct 2019 00:23:18 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/samba%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
			<description>ubuntu 安装 samba服务器
sudo apt-get install samba samba-common  创建目录
mkdir /data/samba chmod 777 /data/samba -R  设置用户名密码(yin是我的用户名)
smbpasswd -a yin  修改 samba配置文件
vim /etc/samba/smb.conf  在文件最后部分添加
[share] comment = share folder browseable = yes path = /data/raid/nextcloud/data/samba #docker目录下的路径 create mask = 0700 directory mask = 0700 valid users = yin #用户名 force user = yin force group = yin public = yes available = yes writable = yes  重启samba服务器</description>
			<content type="html"><![CDATA[<p>ubuntu 安装 samba服务器</p>

<pre><code>sudo apt-get install samba samba-common
</code></pre>

<p>创建目录</p>

<pre><code>mkdir /data/samba
chmod 777 /data/samba -R
</code></pre>

<p>设置用户名密码(yin是我的用户名)</p>

<pre><code>smbpasswd -a yin
</code></pre>

<p>修改 samba配置文件</p>

<pre><code>vim /etc/samba/smb.conf
</code></pre>

<p>在文件最后部分添加</p>

<pre><code>[share]
comment = share folder
browseable = yes
path = /data/raid/nextcloud/data/samba   #docker目录下的路径
create mask = 0700
directory mask = 0700
valid users = yin   #用户名
force user = yin
force group = yin
public = yes
available = yes
writable = yes
</code></pre>

<p>重启samba服务器</p>

<pre><code>service smbd restart
</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Nextcloud添加smb扩展</title>
			<link>https://hrbhot.github.io/posts/nextcloud%E6%B7%BB%E5%8A%A0smb%E6%89%A9%E5%B1%95/</link>
			<pubDate>Tue, 29 Oct 2019 23:37:39 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/nextcloud%E6%B7%BB%E5%8A%A0smb%E6%89%A9%E5%B1%95/</guid>
			<description>添加smb外部存储的支持
在nextcloud应用里面搜索External storage support，打开。 在原有的 nextcloud docker-compose基础上添加了一个启动start.sh
#!/bin/bash set -e VER=0.0.1 docker-compose -f /data/dc/nextcloud/docker-compose.yml up -d docker exec -it nextcloud_nextcloud_1 apt-get update docker exec -it nextcloud_nextcloud_1 apt-get install -y smbclient docker exec -it nextcloud_nextcloud_1 apt-get install -y libsmbclient-dev docker exec -it nextcloud_nextcloud_1 pecl install smbclient  刷新nextcloud页面。</description>
			<content type="html"><![CDATA[<p>添加smb外部存储的支持</p>

<p>在nextcloud应用里面搜索External storage support，打开。
在原有的 nextcloud docker-compose基础上添加了一个启动start.sh</p>

<pre><code>#!/bin/bash
set -e
VER=0.0.1
docker-compose -f /data/dc/nextcloud/docker-compose.yml up -d
docker exec -it nextcloud_nextcloud_1 apt-get update
docker exec -it nextcloud_nextcloud_1 apt-get install -y smbclient
docker exec -it nextcloud_nextcloud_1 apt-get install -y libsmbclient-dev
docker exec -it nextcloud_nextcloud_1 pecl install smbclient
</code></pre>

<p>刷新nextcloud页面。</p>
]]></content>
		</item>
		
		<item>
			<title>Mdada创建raid1分区</title>
			<link>https://hrbhot.github.io/posts/mdada%E5%88%9B%E5%BB%BAraid1%E5%88%86%E5%8C%BA/</link>
			<pubDate>Sun, 27 Oct 2019 23:22:25 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/mdada%E5%88%9B%E5%BB%BAraid1%E5%88%86%E5%8C%BA/</guid>
			<description>用fdisk 把硬盘的分区都删除。
 树形列出硬盘和分区
lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT  创建为md0的 raid1 分区 sdb/sdc是第二块和第三块硬盘
sudo mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sdb /dev/sdc  格式化分区
mkfs.ext4 -F /dev/md0  挂载分区
mkidr -p /data mount /dev/md0 /data  检测分区是否已经正常挂载
df -h -x devtmpfs -x tmpfs  保存自动加载 mdadm配置
mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf  加载到ram里面，在引导可用
update-initramfs -u  添加到启动以便重启自动加载
echo &#39;/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0&#39; | sudo tee -a /etc/fstab   参考来源 https://www.</description>
			<content type="html"><![CDATA[<ol>
<li><p>用fdisk 把硬盘的分区都删除。</p></li>

<li><p>树形列出硬盘和分区</p>

<pre><code>lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT
</code></pre></li>

<li><p>创建为md0的 raid1 分区 sdb/sdc是第二块和第三块硬盘</p>

<pre><code>sudo mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sdb /dev/sdc
</code></pre></li>

<li><p>格式化分区</p>

<pre><code>mkfs.ext4 -F /dev/md0
</code></pre></li>

<li><p>挂载分区</p>

<pre><code>mkidr -p /data
mount /dev/md0 /data
</code></pre></li>

<li><p>检测分区是否已经正常挂载</p>

<pre><code>df -h -x devtmpfs -x tmpfs
</code></pre></li>

<li><p>保存自动加载 mdadm配置</p>

<pre><code>mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf
</code></pre></li>

<li><p>加载到ram里面，在引导可用</p>

<pre><code>update-initramfs -u
</code></pre></li>

<li><p>添加到启动以便重启自动加载</p>

<pre><code>echo '/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0' | sudo tee -a /etc/fstab
</code></pre></li>
</ol>

<p>参考来源
<a href="https://www.chakibhatem.com/2018/11/28/comment-creer-des-matrices-raid-avec-mdadm-sur-ubuntu-18-04/">https://www.chakibhatem.com/2018/11/28/comment-creer-des-matrices-raid-avec-mdadm-sur-ubuntu-18-04/</a></p>
]]></content>
		</item>
		
		<item>
			<title>Mac下grep 使用查找某文件包含的内容</title>
			<link>https://hrbhot.github.io/posts/mac%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E5%86%85%E5%8C%85%E5%90%AB%E7%9A%84%E6%96%87%E5%AD%97/</link>
			<pubDate>Sun, 27 Oct 2019 20:10:36 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/mac%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E5%86%85%E5%8C%85%E5%90%AB%E7%9A%84%E6%96%87%E5%AD%97/</guid>
			<description>grep -n &amp;ldquo;文件内容&amp;rdquo; -r ./</description>
			<content type="html"><![CDATA[<p>grep -n &ldquo;文件内容&rdquo; -r ./</p>
]]></content>
		</item>
		
		<item>
			<title>Nextcloud</title>
			<link>https://hrbhot.github.io/posts/nextcloud/</link>
			<pubDate>Sun, 27 Oct 2019 19:38:11 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/nextcloud/</guid>
			<description>nextcloud docker-compose 安装
 下载docker-compose 的nextcloud脚本
git clone https://github.com/wahyd4/aria2-ariang-x-docker-compose.git  进入nextcloud目录
cd aria2-ariang-x-docker-compose/nextcloud  拉docker镜像以及检测是否有错误。
docker-compose up  修改 data目录权限，否则会报502错误，或者 “Your data directory is readable by other users ”
chown -R www-data data chmod -R 0770 daTA  运行nextcloud ,并到前端注册用户名密码。完成。
docker-compose up -d  补充 修改 nextcloud/config/config.php 文件，添加
&#39;check_data_directory_permissions&#39; =&amp;gt; false,  否则不是出现502错误，就是500错误。
  </description>
			<content type="html"><![CDATA[<p>nextcloud docker-compose 安装</p>

<ol>
<li><p>下载docker-compose 的nextcloud脚本</p>

<pre><code>git clone https://github.com/wahyd4/aria2-ariang-x-docker-compose.git
</code></pre></li>

<li><p>进入nextcloud目录</p>

<pre><code>cd aria2-ariang-x-docker-compose/nextcloud
</code></pre></li>

<li><p>拉docker镜像以及检测是否有错误。</p>

<pre><code>docker-compose up 
</code></pre></li>

<li><p>修改 data目录权限，否则会报502错误，或者 “Your data directory is readable by other users ”</p>

<pre><code>chown -R www-data data
chmod -R 0770 daTA
</code></pre></li>

<li><p>运行nextcloud ,并到前端注册用户名密码。完成。</p>

<pre><code>docker-compose up -d
</code></pre>

<p>补充
修改 nextcloud/config/config.php 文件，添加</p>

<pre><code>'check_data_directory_permissions' =&gt; false,
</code></pre>

<p>否则不是出现502错误，就是500错误。</p></li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>使用ddns把动态ip绑定到域名</title>
			<link>https://hrbhot.github.io/posts/%E4%BD%BF%E7%94%A8ddns%E7%BB%91%E5%AE%9A%E5%8A%A8%E6%80%81ip%E5%88%B0%E5%9F%9F%E5%90%8D/</link>
			<pubDate>Sun, 27 Oct 2019 17:34:25 +0100</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E4%BD%BF%E7%94%A8ddns%E7%BB%91%E5%AE%9A%E5%8A%A8%E6%80%81ip%E5%88%B0%E5%9F%9F%E5%90%8D/</guid>
			<description>公司的box是orange business，竟然不是固定ip。最近折腾内网的nas因为这个事情折腾了2天。 方案是用 ddns https://github.com/NewFuture/DDNS
 申请腾讯的DNSPOD，把域名添加到里面，然后到现有到域名商那里自定义dns添加f1g1ns1.dnspod.net， f1g1ns2.dnspod.net 。
 在DNSPOD密钥管理里面，添加API ，记住ID和TOKEN字段。
 用pip 安装 ddns
pip install ddns  编辑config.json文件 id -&amp;gt; DNSPOD API id, ipv4 -&amp;gt; 修改为自己的域名 index4 -&amp;gt; &amp;ldquo;public&amp;rdquo; ipv6 -&amp;gt; 清空变成 [] tokend -&amp;gt; DNSPOD API token
 执行ddns 命令,提示域名已经指向了当前的动态ip地址。这是在DNSPOD的控制台也可以看到这时候IP已经变成了box的动态ip。
 定时任务，需要把github clone到本地,给task.sh和run.py加权限运行。
运行 cat /etc/cron.d/ddns  任务已经添加到了cron
  </description>
			<content type="html"><![CDATA[<p>公司的box是orange business，竟然不是固定ip。最近折腾内网的nas因为这个事情折腾了2天。
方案是用 ddns <a href="https://github.com/NewFuture/DDNS">https://github.com/NewFuture/DDNS</a></p>

<ol>
<li><p>申请腾讯的DNSPOD，把域名添加到里面，然后到现有到域名商那里自定义dns添加f1g1ns1.dnspod.net， f1g1ns2.dnspod.net 。</p></li>

<li><p>在DNSPOD密钥管理里面，添加API ，记住ID和TOKEN字段。</p></li>

<li><p>用pip 安装 ddns</p>

<pre><code>pip install ddns
</code></pre></li>

<li><p>编辑config.json文件
id -&gt; DNSPOD API id,
ipv4 -&gt; 修改为自己的域名
index4 -&gt; &ldquo;public&rdquo;
ipv6 -&gt; 清空变成 []
tokend -&gt; DNSPOD API token</p></li>

<li><p>执行ddns 命令,提示域名已经指向了当前的动态ip地址。这是在DNSPOD的控制台也可以看到这时候IP已经变成了box的动态ip。</p></li>

<li><p>定时任务，需要把github clone到本地,给task.sh和run.py加权限运行。</p>

<pre><code>运行 cat  /etc/cron.d/ddns
</code></pre>

<p>任务已经添加到了cron</p></li>
</ol>
]]></content>
		</item>
		
		<item>
			<title>Centos安装docker的错误解决</title>
			<link>https://hrbhot.github.io/posts/centos/</link>
			<pubDate>Tue, 22 Oct 2019 23:44:51 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/centos/</guid>
			<description>为了保持多样性，新弄的服务器装成了centos，安装docker的时候出现了一个小问题。 按照官方向导在运行
sudo yum install docker-ce docker-ce-cli containerd.io  出现了以下错误
package docker-ce-3:19.03.4-3.el7.x86_64 requires containerd.io &amp;gt;= 1.2.2-3, but none of the providers can be installed  解决办法是先运行了
yum update  来升级当前系统，之后用dnf安装
dnf install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm  然后再安装官方步骤走即可，直到运行
 sudo docker run hello-world  </description>
			<content type="html"><![CDATA[<p>为了保持多样性，新弄的服务器装成了centos，安装docker的时候出现了一个小问题。
按照官方向导在运行</p>

<pre><code>sudo yum install docker-ce docker-ce-cli containerd.io  
</code></pre>

<p>出现了以下错误</p>

<pre><code>package docker-ce-3:19.03.4-3.el7.x86_64 requires containerd.io &gt;= 1.2.2-3, but none of the providers can be installed
</code></pre>

<p>解决办法是先运行了</p>

<pre><code>yum update
</code></pre>

<p>来升级当前系统，之后用dnf安装</p>

<pre><code>dnf install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm
</code></pre>

<p>然后再安装官方步骤走即可，直到运行</p>

<pre><code> sudo docker run hello-world

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>在phpmyadmin中用sql语句修改root密码</title>
			<link>https://hrbhot.github.io/posts/%E5%9C%A8phpmyadmin%E4%B8%AD%E7%94%A8sql%E8%AF%AD%E5%8F%A5%E4%BF%AE%E6%94%B9root%E5%AF%86%E7%A0%81/</link>
			<pubDate>Sun, 20 Oct 2019 22:35:54 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E5%9C%A8phpmyadmin%E4%B8%AD%E7%94%A8sql%E8%AF%AD%E5%8F%A5%E4%BF%AE%E6%94%B9root%E5%AF%86%E7%A0%81/</guid>
			<description>为了统一实验环境，需要修改docker 的mysql密码 ，之前有安装phpmyadmin 之前用sql语句修改。
update user set authentication_string=PASSWORD(&amp;quot;password&amp;quot;) where User=&#39;root&#39;;  </description>
			<content type="html"><![CDATA[<p>为了统一实验环境，需要修改docker 的mysql密码 ，之前有安装phpmyadmin 之前用sql语句修改。</p>

<pre><code>update user set authentication_string=PASSWORD(&quot;password&quot;) where User='root';

</code></pre>
]]></content>
		</item>
		
		<item>
			<title>Mac环境docker访问宿主机ip</title>
			<link>https://hrbhot.github.io/posts/mac%E7%8E%AF%E5%A2%83docker%E8%AE%BF%E9%97%AE%E5%AE%BF%E4%B8%BB%E6%9C%BAip/</link>
			<pubDate>Sun, 20 Oct 2019 22:32:04 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/mac%E7%8E%AF%E5%A2%83docker%E8%AE%BF%E9%97%AE%E5%AE%BF%E4%B8%BB%E6%9C%BAip/</guid>
			<description>mac测试环境下遇到一个问题，不能访问宿主机的端口。开始的时候错误的用127.0.0.1的地址访问，访问的是docker内容器的地址。 正确的方法是用
 docker.for.mac.host.internal  这个地址来访问</description>
			<content type="html"><![CDATA[<p>mac测试环境下遇到一个问题，不能访问宿主机的端口。开始的时候错误的用127.0.0.1的地址访问，访问的是docker内容器的地址。
正确的方法是用</p>

<pre><code> docker.for.mac.host.internal 
</code></pre>

<p>这个地址来访问</p>
]]></content>
		</item>
		
		<item>
			<title>Docker迁移mysql的数据问题</title>
			<link>https://hrbhot.github.io/posts/docker%E8%BF%81%E7%A7%BBmysql%E7%9A%84%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</link>
			<pubDate>Sun, 20 Oct 2019 20:46:33 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/docker%E8%BF%81%E7%A7%BBmysql%E7%9A%84%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/</guid>
			<description>今天周日难得有空闲，把之前的joomla 1.5 迁移到本地环境测试升级到version 3. 在迁移过程中 遇到了mysql 错误。
 [ERROR] --initialize specified but the data directory has files in it. Aborting.  解决的办法是，要把之前的mysql 数据先转移到一个临时文件夹，然后运行 Docker-compose up 生成镜像。再把mysql数据cp回来。
用docker-compose迁移一个mysql php nginx的joomla网站到本地环境 15分钟内搞定。</description>
			<content type="html"><![CDATA[<p>今天周日难得有空闲，把之前的joomla 1.5 迁移到本地环境测试升级到version 3.
在迁移过程中 遇到了mysql 错误。</p>

<pre><code> [ERROR] --initialize specified but the data directory has files in it. Aborting.

</code></pre>

<p>解决的办法是，要把之前的mysql 数据先转移到一个临时文件夹，然后运行 Docker-compose up 生成镜像。再把mysql数据cp回来。</p>

<p>用docker-compose迁移一个mysql php nginx的joomla网站到本地环境 15分钟内搞定。</p>
]]></content>
		</item>
		
		<item>
			<title>备忘录的安装记录</title>
			<link>https://hrbhot.github.io/posts/%E5%A4%87%E5%BF%98%E5%BD%95%E7%9A%84%E5%AE%89%E8%A3%85/</link>
			<pubDate>Sun, 20 Oct 2019 13:58:38 +0200</pubDate>
			
			<guid>https://hrbhot.github.io/posts/%E5%A4%87%E5%BF%98%E5%BD%95%E7%9A%84%E5%AE%89%E8%A3%85/</guid>
			<description> 1. 安装go hugo git clone https://github.com/gohugoio/hugo.git cd hugo go install  2. 设置主题 git submodule add https://github.com/panr/hugo-theme-hello-friend.git themes/hello echo &#39;theme = &amp;quot;hello&amp;quot;&#39; &amp;gt;&amp;gt; config.toml  3. 发布文章 hugo new posts/my-first-post.md  4. 启动预览 hugo server hugo server -D # 草稿 draft 为true的文章  5. 部署项目 上传public内的文件到hrbhot.github.io项目 cd public git init git add . git commit -m &#39;for init blog&#39; git remote add origin git@github.com:hrbhot/hrbhot.github.io.git #替换成自己的git name git push -u origin master  </description>
			<content type="html"><![CDATA[

<h2 id="1-安装go-hugo">1. 安装go hugo</h2>

<pre><code>git clone https://github.com/gohugoio/hugo.git
cd hugo
go install
</code></pre>

<h2 id="2-设置主题">2. 设置主题</h2>

<pre><code>git submodule add https://github.com/panr/hugo-theme-hello-friend.git themes/hello
echo 'theme = &quot;hello&quot;' &gt;&gt; config.toml

</code></pre>

<h2 id="3-发布文章">3. 发布文章</h2>

<pre><code>hugo new posts/my-first-post.md
</code></pre>

<h2 id="4-启动预览">4. 启动预览</h2>

<pre><code>hugo server
hugo server -D # 草稿 draft 为true的文章
</code></pre>

<h2 id="5-部署项目">5. 部署项目</h2>

<pre><code>上传public内的文件到hrbhot.github.io项目
cd public
git init
git add .
git commit -m 'for init blog'
git remote add origin git@github.com:hrbhot/hrbhot.github.io.git #替换成自己的git name
git push -u origin master
</code></pre>
]]></content>
		</item>
		
	</channel>
</rss>
